# python
"""
planner_agent.py - PlannerAgent æ ¸å¿ƒå®ç°ï¼ˆä¿ç•™åŸæœ‰æ•°æ®ç»“æ„ï¼‰
===========================================================

åŠŸèƒ½ï¼šæœ¬å­¦æœŸè¯¾ç¨‹è§„åˆ’å’Œå¤ä¹ è®¡åˆ’ç”Ÿæˆï¼ˆåŸºäº RAG + LLM æ¶æ„ï¼‰

æ ¸å¿ƒç‰¹ç‚¹ï¼š
1. å®Œæ•´çš„ RAG æ¶æ„å®ç°ï¼ˆæ£€ç´¢ + å¢å¼º + ç”Ÿæˆï¼‰
2. LLM é…ç½®çµæ´»ï¼Œæ”¯æŒæœ¬åœ°æ¨¡å‹ï¼ˆOllama, vLLM, è‡ªå®šä¹‰ APIï¼‰
3. ä¸“æ³¨äºæœ¬å­¦æœŸè§„åˆ’ï¼ˆ9-12æœˆï¼‰
4. æ‰€æœ‰å‚æ•°å¯åæœŸä¿®æ”¹ï¼Œæ— éœ€å†™æ­»
5. ä¿ç•™åŸæœ‰çš„æ•°æ®ç»“æ„ï¼Œä¸åšæ›´æ”¹

æ•°æ®ç»“æ„ç”± init.py å®šä¹‰ï¼Œè¿™é‡Œåªå®ç° Agent çš„æ–¹æ³•
"""

from datetime import datetime, timedelta,date as _date
from typing import Dict, List, Optional, Any
import requests
import json
import re


from dao import (
    UserCourseDAO,
    CourseDAO, AssignmentDAO,
StudySessionDAO
)
from models import ActionInput, ActionResult, ScheduleResult,ScheduleInput,ProgressQuery,ProgressResult


class LLMConfig:
    """LLM é…ç½®ç±» - æ”¯æŒå¤šç§æ¨¡å‹å’Œæä¾›å•†"""

    def __init__(
            self,
            provider: str = "openai",
            base_url: str = None,
            api_key: str = None,
            model: str = "gpt-4",
            temperature: float = 0.7,
            max_tokens: int = 2500,
            timeout: int = 30
    ):
        self.provider = provider
        self.base_url = base_url
        self.api_key = api_key
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.timeout = timeout

    @staticmethod
    def openai_api(api_key: str, model: str = "gpt-4") -> "LLMConfig":
        return LLMConfig(provider="openai", api_key=api_key, model=model, base_url="https://api.openai.com/v1")

    @staticmethod
    def local_ollama(base_url: str = "http://localhost:11434", model: str = "qwen2:7b") -> "LLMConfig":
        return LLMConfig(provider="ollama", base_url=base_url, model=model)

    @staticmethod
    def local_vllm(base_url: str = "http://localhost:8000", model: str = "meta-llama/Llama-2-7b-hf") -> "LLMConfig":
        return LLMConfig(provider="vllm", base_url=base_url, model=model)

    @staticmethod
    def local_api(base_url: str, model: str = "local-model") -> "LLMConfig":
        return LLMConfig(provider="local_api", base_url=base_url, model=model)

    def to_dict(self) -> Dict:
        return {
            'provider': self.provider,
            'base_url': self.base_url,
            'api_key': self.api_key if self.api_key and len(self.api_key) > 10 else '***',
            'model': self.model,
            'temperature': self.temperature,
            'max_tokens': self.max_tokens,
            'timeout': self.timeout
        }


class PlannerAgent:
    """å­¦æœŸè§„åˆ’æ™ºèƒ½ä½“ï¼ˆRAG + LLM + é…ç½®åŒ– + æœ¬å­¦æœŸä¸“æ³¨ï¼‰"""

    def __init__(
            self,
            llm_config: LLMConfig = None,
            openai_api_key: str = None,
            current_semester: str = "2025-Fall"
    ):
        self.current_semester = current_semester
        self.semester_months = [9, 10, 11, 12]

        # åˆå§‹åŒ– DAO
        self.user_course_dao = UserCourseDAO()
        self.course_dao = CourseDAO()
        self.assignment_dao = AssignmentDAO()
        self.study_session_dao = StudySessionDAO()

        # é…ç½® LLM
        if llm_config:
            self.llm_config = llm_config
        elif openai_api_key:
            self.llm_config = LLMConfig.openai_api(openai_api_key)
        else:
            self.llm_config = LLMConfig.local_ollama()

    # ================================================================
    # LLM è°ƒç”¨æ–¹æ³•ï¼ˆæ”¯æŒå¤šä¸ªæä¾›å•†ï¼‰
    # ================================================================

    def call_llm(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨ LLM APIï¼ˆæ”¯æŒå¤šä¸ªæä¾›å•†ï¼‰"""
        try:
            if self.llm_config.provider == "openai":
                return self._call_openai(system_prompt, user_prompt)
            elif self.llm_config.provider == "ollama":
                return self._call_ollama(system_prompt, user_prompt)
            elif self.llm_config.provider == "vllm":
                return self._call_vllm(system_prompt, user_prompt)
            elif self.llm_config.provider == "local_api":
                return self._call_local_api(system_prompt, user_prompt)
            else:
                return f"é”™è¯¯ï¼šä¸æ”¯æŒçš„æä¾›å•† {self.llm_config.provider}"
        except Exception as e:
            print(f"LLM è°ƒç”¨å¤±è´¥: {e}")
            return f"é”™è¯¯ï¼šæ— æ³•ç”Ÿæˆå›ç­”ã€‚{str(e)}"

    def _call_openai(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨ OpenAI API"""
        import openai
        openai.api_key = self.llm_config.api_key
        response = openai.ChatCompletion.create(
            model=self.llm_config.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=self.llm_config.temperature,
            max_tokens=self.llm_config.max_tokens
        )
        return response['choices'][0]['message']['content']

    def _call_ollama(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨æœ¬åœ° Ollama"""
        url = f"{self.llm_config.base_url}/api/chat"
        payload = {
            "model": self.llm_config.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": self.llm_config.temperature,
            "stream": False
        }
        response = requests.post(url, json=payload, timeout=self.llm_config.timeout)
        if response.status_code == 200:
            return response.json()['message']['content']
        else:
            raise Exception(f"Ollama API é”™è¯¯: {response.status_code}")

    def _call_vllm(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨æœ¬åœ° vLLM"""
        url = f"{self.llm_config.base_url}/v1/chat/completions"
        payload = {
            "model": self.llm_config.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": self.llm_config.temperature,
            "max_tokens": self.llm_config.max_tokens
        }
        response = requests.post(url, json=payload, timeout=self.llm_config.timeout)
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        else:
            raise Exception(f"vLLM API é”™è¯¯: {response.status_code}")

    def _call_local_api(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨æœ¬åœ°é€šç”¨ API"""
        url = f"{self.llm_config.base_url}/chat"
        payload = {
            "model": self.llm_config.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": self.llm_config.temperature,
            "max_tokens": self.llm_config.max_tokens
        }
        response = requests.post(url, json=payload, timeout=self.llm_config.timeout)
        if response.status_code == 200:
            result = response.json()
            if 'content' in result:
                return result['content']
            elif 'message' in result:
                return result['message']
            else:
                return str(result)
        else:
            raise Exception(f"æœ¬åœ° API é”™è¯¯: {response.status_code}")

    # ================================================================
    # é…ç½®ç®¡ç†æ–¹æ³•
    # ================================================================

    def update_llm_config(self, **kwargs) -> None:
        """åŠ¨æ€æ›´æ–° LLM é…ç½®ï¼ˆåæœŸå¯ä¿®æ”¹ï¼Œæ— éœ€é‡æ–°åˆå§‹åŒ–ï¼‰"""
        for key, value in kwargs.items():
            if hasattr(self.llm_config, key):
                setattr(self.llm_config, key, value)

    def get_llm_config(self) -> Dict:
        """è·å–å½“å‰ LLM é…ç½®"""
        return self.llm_config.to_dict()

    #
    # def chat(self, user_id: int, message: str) -> str:
    #
    # # ================================================================
    # # æ–°å¢æ–¹æ³•ï¼šsuggest() - æä¾›å­¦ä¹ å»ºè®®
    # # ================================================================
    #
    # def suggest(self, task_desc: str, resources: List[str] = None, user_id: int = None) -> Dict:
    #
    #
    # # ================================================================
    # # æ–°å¢æ–¹æ³•ï¼šschedule() - ç”Ÿæˆæ—¥ç¨‹å®‰æ’
    # # ================================================================
    #

    # python
    def schedule(self, scheduleInput: "ScheduleInput") -> "ScheduleResult":
        """
        æ™ºèƒ½æ—¥ç¨‹å®‰æ’Agent - ä½¿ç”¨é…ç½®çš„LLMè¿›è¡Œæ™ºèƒ½è§„åˆ’
        """
        try:
            user_id = getattr(scheduleInput, 'user_id', None)
            tasks = getattr(scheduleInput, 'tasks', [])
            date_range = getattr(scheduleInput, 'date_range', None)

            if not user_id:
                return ScheduleResult(schedule=[{
                    'type': 'error',
                    'content': 'éœ€è¦ç”¨æˆ·ID'
                }])

            print(f"ğŸ” å¼€å§‹æ™ºèƒ½æ—¥ç¨‹è§„åˆ’ - ç”¨æˆ·: {user_id}, ä»»åŠ¡æ•°: {len(tasks)}")
            print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {self.llm_config.model}")

            # 1. è·å–åŸºç¡€æ•°æ®
            relevant_data = self._get_relevant_data(user_id, date_range)

            # 2. ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½è§„åˆ’ï¼ˆå¦‚æœLLMå¯ç”¨ï¼‰
            if self.llm_config.provider != "unknown":
                try:
                    ai_plan = self._generate_intelligent_plan(tasks, relevant_data, user_id)
                    return self._create_ai_schedule_response(ai_plan, relevant_data, tasks)
                except Exception as e:
                    print(f"âš ï¸ LLMè§„åˆ’å¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ: {e}")
                    return self._create_fallback_schedule(relevant_data, tasks)
            else:
                # LLMä¸å¯ç”¨ï¼Œä½¿ç”¨è§„åˆ™åŸºç¡€æ–¹æ¡ˆ
                return self._create_rule_based_schedule(relevant_data, tasks)

        except Exception as e:
            print(f"âŒ æ—¥ç¨‹è§„åˆ’é”™è¯¯: {e}")
            return ScheduleResult(schedule=[{
                'type': 'error',
                'content': f'è§„åˆ’å¤±è´¥: {str(e)}'
            }])

    def _get_relevant_data(self, user_id: int, date_range: str) -> Dict:
        """è·å–ç›¸å…³æ•°æ®"""
        from datetime import datetime, timedelta

        # è§£ææ—¥æœŸèŒƒå›´
        if date_range and ' to ' in date_range:
            start_str, end_str = date_range.split(' to ')
            start_date = datetime.strptime(start_str.strip(), '%Y-%m-%d')
            end_date = datetime.strptime(end_str.strip(), '%Y-%m-%d')
        else:
            start_date = datetime.now()
            end_date = start_date + timedelta(days=30)

        assignments = self.assignment_dao.get_assignments_by_date_range(user_id, start_date, end_date)
        study_sessions = self.study_session_dao.get_study_sessions_by_date_range(user_id, start_date, end_date)

        return {
            'assignments': assignments,
            'study_sessions': study_sessions,
            'date_range': {'start': start_date, 'end': end_date}
        }

    def _generate_intelligent_plan(self, tasks: List[str], relevant_data: Dict, user_id: int) -> Dict:
        """ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½è§„åˆ’"""

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å­¦ä¹ è§„åˆ’åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·çš„ä»»åŠ¡å’Œç°æœ‰çš„å­¦ä¹ æ•°æ®ï¼Œç”Ÿæˆåˆç†çš„æ—¥ç¨‹å®‰æ’å»ºè®®ã€‚

    è¯·è€ƒè™‘ï¼š
    1. ä»»åŠ¡çš„ä¼˜å…ˆçº§å’Œå¤æ‚åº¦
    2. åˆç†çš„æ—¶é—´åˆ†é…
    3. å­¦ä¹ æ•ˆç‡å»ºè®®
    4. å…·ä½“çš„æ‰§è¡Œæ­¥éª¤

    ç”¨ä¸­æ–‡å›å¤ï¼Œæ ¼å¼æ¸…æ™°æ˜“è¯»ã€‚"""

        tasks_text = "\n".join([f"- {task}" for task in tasks])
        assignments_text = "\n".join([
            f"- {a.get('title', '')} (æˆªæ­¢: {a.get('due_date')}, çŠ¶æ€: {a.get('status', 'pending')})"
            for a in relevant_data['assignments'][:5]  # é™åˆ¶æ•°é‡é¿å…è¿‡é•¿
        ])

        user_prompt = f"""è¯·ä¸ºä»¥ä¸‹å­¦ä¹ ä»»åŠ¡ç”Ÿæˆæ—¥ç¨‹å®‰æ’ï¼š

    å¾…åŠä»»åŠ¡ï¼š
    {tasks_text}

    ç°æœ‰ä½œä¸šï¼š
    {assignments_text}

    æ—¶é—´èŒƒå›´ï¼š{relevant_data['date_range']['start'].strftime('%Y-%m-%d')} åˆ° {relevant_data['date_range']['end'].strftime('%Y-%m-%d')}

    è¯·æä¾›ä¸€ä¸ªå®ç”¨çš„å­¦ä¹ è®¡åˆ’ï¼ŒåŒ…æ‹¬æ—¶é—´å®‰æ’å’Œä¼˜å…ˆçº§å»ºè®®ã€‚"""

        print("ğŸ§  è°ƒç”¨LLMç”Ÿæˆæ™ºèƒ½è§„åˆ’...")
        ai_response = self.call_llm(system_prompt, user_prompt)

        return {
            'ai_recommendation': ai_response,
            'tasks_analyzed': len(tasks),
            'assignments_considered': len(relevant_data['assignments'])
        }

    def _create_ai_schedule_response(self, ai_plan: Dict, relevant_data: Dict, tasks: List[str]) -> "ScheduleResult":
        """åˆ›å»ºAIå¢å¼ºçš„æ—¥ç¨‹å“åº”"""

        schedule_items = []

        # 1. AIå»ºè®®
        schedule_items.append({
            'type': 'ai_recommendation',
            'content': ai_plan['ai_recommendation'],
            'source': 'llm',
            'tasks_analyzed': ai_plan['tasks_analyzed']
        })

        # 2. å…·ä½“ä»»åŠ¡å®‰æ’
        for i, task in enumerate(tasks):
            schedule_items.append({
                'type': 'scheduled_task',
                'task_id': i + 1,
                'title': task,
                'suggested_order': i + 1,
                'estimated_duration_minutes': 60,  # é»˜è®¤1å°æ—¶
                'priority': 'high' if i == 0 else 'medium'
            })

        # 3. æ•°æ®ç»Ÿè®¡
        schedule_items.append({
            'type': 'summary',
            'total_tasks': len(tasks),
            'upcoming_assignments': len(relevant_data['assignments']),
            'study_sessions': len(relevant_data['study_sessions']),
            'date_range': f"{relevant_data['date_range']['start'].strftime('%Y-%m-%d')} åˆ° {relevant_data['date_range']['end'].strftime('%Y-%m-%d')}"
        })

        return ScheduleResult(schedule=schedule_items)

    def _create_fallback_schedule(self, relevant_data: Dict, tasks: List[str]) -> "ScheduleResult":
        """LLMå¤±è´¥æ—¶çš„å›é€€æ–¹æ¡ˆ"""
        schedule_items = []

        schedule_items.append({
            'type': 'info',
            'content': 'åŸºäºç°æœ‰æ•°æ®çš„æ—¥ç¨‹å®‰æ’ï¼ˆAIè§„åˆ’æš‚ä¸å¯ç”¨ï¼‰'
        })

        # ç®€å•çš„ä»»åŠ¡å®‰æ’
        for i, task in enumerate(tasks):
            schedule_items.append({
                'type': 'task',
                'title': task,
                'order': i + 1,
                'suggested_time': f'ç¬¬{i + 1}å¤©'
            })

        return ScheduleResult(schedule=schedule_items)

    def _analyze_schedule_intent(self, query: str, date_range: str, user_id: int) -> Dict:
        """ä½¿ç”¨LLMåˆ†æç”¨æˆ·æŸ¥è¯¢çš„æ·±å±‚æ„å›¾"""

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å­¦ä¹ è§„åˆ’åŠ©æ‰‹ã€‚è¯·åˆ†æç”¨æˆ·çš„æ—¥ç¨‹æŸ¥è¯¢è¯·æ±‚ï¼Œç†è§£å…¶æ·±å±‚æ„å›¾å’Œéœ€æ±‚ã€‚

    è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š
    1. ä¸»è¦æ„å›¾ï¼ˆè€ƒè¯•å‡†å¤‡ã€ä½œä¸šè§„åˆ’ã€å­¦ä¹ å®‰æ’ã€å¤ä¹ è®¡åˆ’ç­‰ï¼‰
    2. æ—¶é—´ç´§è¿«ç¨‹åº¦
    3. ç”¨æˆ·å¯èƒ½çš„éšè—éœ€æ±‚
    4. æ¨èçš„è§„åˆ’ç­–ç•¥

    è¿”å›JSONæ ¼å¼ï¼š{
        "intent": "è€ƒè¯•å‡†å¤‡|ä½œä¸šè§„åˆ’|å­¦ä¹ å®‰æ’|å¤ä¹ è®¡åˆ’",
        "urgency": "é«˜|ä¸­|ä½",
        "time_range": {"start": "...", "end": "..."},
        "hidden_needs": ["..."],
        "planning_strategy": "...",
        "focus_courses": ["è¯¾ç¨‹å"],
        "priority_tasks": ["ä»»åŠ¡ç±»å‹"]
    }"""

        user_prompt = f"""
    ç”¨æˆ·æŸ¥è¯¢: {query}
    æ—¶é—´èŒƒå›´: {date_range}
    ç”¨æˆ·ID: {user_id}

    å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}

    è¯·åˆ†æè¿™ä¸ªæ—¥ç¨‹æŸ¥è¯¢è¯·æ±‚ã€‚
    """

        response = self.call_llm(system_prompt, user_prompt)

        try:
            return json.loads(response)
        except:
            # å¦‚æœLLMè¿”å›éJSONï¼Œä½¿ç”¨è§„åˆ™å›é€€
            return self._fallback_intent_analysis(query, date_range)

    def _intelligent_data_retrieval(self, intent_analysis: Dict, user_id: int) -> Dict:
        """åŸºäºæ„å›¾åˆ†ææ™ºèƒ½æ£€ç´¢ç›¸å…³æ•°æ®"""

        # æ ¹æ®åˆ†æç»“æœåŠ¨æ€è°ƒæ•´æŸ¥è¯¢ç­–ç•¥
        intent = intent_analysis.get('intent', '')
        focus_courses = intent_analysis.get('focus_courses', [])
        urgency = intent_analysis.get('urgency', 'ä¸­')

        # åŠ¨æ€è®¡ç®—æ—¶é—´èŒƒå›´
        days_to_look = self._calculate_time_range_based_on_urgency(urgency)
        end_date = datetime.now() + timedelta(days=days_to_look)

        # è·å–åŸºç¡€æ•°æ®
        assignments = self.assignment_dao.get_assignments_by_date_range(
            user_id, datetime.now(), end_date
        )

        study_sessions = self.study_session_dao.get_study_sessions_by_date_range(
            user_id, datetime.now(), end_date
        )

        # æ ¹æ®æ„å›¾è¿‡æ»¤å’Œå¢å¼ºæ•°æ®
        if intent == "è€ƒè¯•å‡†å¤‡":
            exams = self.assignment_dao.get_assignments_by_type(user_id, 'exam')
            # è·å–ç›¸å…³çš„å­¦ä¹ å†å²
            exam_prep_sessions = self._get_exam_preparation_sessions(user_id, focus_courses)
            return {
                "assignments": exams,
                "study_sessions": exam_prep_sessions,
                "data_type": "exam_focused"
            }

        elif intent == "ä½œä¸šè§„åˆ’":
            # é‡ç‚¹å…³æ³¨pendingçŠ¶æ€çš„ä½œä¸š
            pending_assignments = [a for a in assignments if a.get('status') != 'completed']
            return {
                "assignments": pending_assignments,
                "study_sessions": study_sessions,
                "data_type": "homework_focused"
            }

        else:
            return {
                "assignments": assignments,
                "study_sessions": study_sessions,
                "data_type": "general"
            }

    def _generate_ai_schedule(self, intent_analysis: Dict, relevant_data: Dict, user_id: int) -> Dict:
        """ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½æ—¥ç¨‹è§„åˆ’"""

        system_prompt = """ä½ æ˜¯ä¸“ä¸šçš„å­¦ä¹ è§„åˆ’ä¸“å®¶ã€‚åŸºäºç”¨æˆ·çš„å­¦ä¹ æ•°æ®å’ŒæŸ¥è¯¢æ„å›¾ï¼Œç”Ÿæˆä¸ªæ€§åŒ–çš„æ—¥ç¨‹å®‰æ’å»ºè®®ã€‚

    è¯·è€ƒè™‘ï¼š
    1. ä»»åŠ¡çš„ä¼˜å…ˆçº§å’Œæˆªæ­¢æ—¥æœŸ
    2. å­¦ä¹ å†å²çš„æ¨¡å¼å’Œæ•ˆç‡
    3. åˆç†çš„æ—¶é—´åˆ†é…å’Œä¼‘æ¯å®‰æ’
    4. å…·ä½“å¯æ‰§è¡Œçš„è¡ŒåŠ¨å»ºè®®

    è¿”å›ç»“æ„åŒ–çš„æ—¥ç¨‹è§„åˆ’ã€‚"""

        # å‡†å¤‡ä¸Šä¸‹æ–‡æ•°æ®
        context_data = {
            "intent_analysis": intent_analysis,
            "upcoming_assignments": relevant_data.get("assignments", [])[:10],  # é™åˆ¶æ•°é‡
            "recent_study_patterns": self._analyze_study_patterns(relevant_data.get("study_sessions", [])),
            "user_learning_profile": self._get_user_learning_profile(user_id)
        }

        user_prompt = f"""
    åŸºäºä»¥ä¸‹ä¿¡æ¯ä¸ºç”¨æˆ·ç”Ÿæˆæ™ºèƒ½æ—¥ç¨‹å®‰æ’ï¼š

    ç”¨æˆ·æ„å›¾åˆ†æ: {intent_analysis}
    è¿‘æœŸä»»åŠ¡: {[f"{a['title']} (æˆªæ­¢: {a.get('due_date')})" for a in context_data['upcoming_assignments']]}
    å­¦ä¹ æ¨¡å¼: {context_data['recent_study_patterns']}
    ç”¨æˆ·å­¦ä¹ ç‰¹å¾: {context_data['user_learning_profile']}

    è¯·ç”Ÿæˆä¸€ä¸ªå…·ä½“ã€å¯è¡Œã€ä¸ªæ€§åŒ–çš„æ—¥ç¨‹å®‰æ’è®¡åˆ’ã€‚
    """

        ai_response = self.call_llm(system_prompt, user_prompt)

        return {
            "ai_recommendations": ai_response,
            "reasoning": "åŸºäºå­¦ä¹ æ•°æ®å’Œç”¨æˆ·æ„å›¾çš„æ™ºèƒ½è§„åˆ’",
            "confidence_score": self._calculate_confidence(intent_analysis, relevant_data)
        }

    def _format_schedule_response(self, ai_schedule: Dict, relevant_data: Dict,
                                  intent_analysis: Dict) -> "ScheduleResult":
        """æ ¼å¼åŒ–æœ€ç»ˆçš„æ™ºèƒ½å“åº”"""

        schedule_items = []

        # 1. æ·»åŠ AIç”Ÿæˆçš„å»ºè®®
        schedule_items.append({
            'type': 'ai_recommendation',
            'content': ai_schedule.get("ai_recommendations", ""),
            'intent': intent_analysis.get("intent"),
            'confidence': ai_schedule.get("confidence_score", 0.7),
            'strategy': intent_analysis.get("planning_strategy")
        })

        # 2. æ·»åŠ å…·ä½“ä»»åŠ¡å®‰æ’ï¼ˆåŸºäºAIå»ºè®®è¿›ä¸€æ­¥ç»“æ„åŒ–ï¼‰
        structured_plan = self._extract_structured_plan(ai_schedule.get("ai_recommendations", ""))
        for plan_item in structured_plan:
            schedule_items.append({
                'type': 'scheduled_task',
                'title': plan_item.get('task'),
                'suggested_time': plan_item.get('time'),
                'priority': plan_item.get('priority'),
                'estimated_duration': plan_item.get('duration'),
                'reasoning': plan_item.get('reasoning')
            })

        # 3. æ·»åŠ æ•°æ®æ”¯æ’‘
        schedule_items.append({
            'type': 'data_backing',
            'upcoming_count': len(relevant_data.get("assignments", [])),
            'recent_study_hours': self._calculate_recent_study_hours(relevant_data.get("study_sessions", [])),
            'urgency_level': intent_analysis.get("urgency")
        })

        return ScheduleResult(schedule=schedule_items)

    def _calculate_time_range_based_on_urgency(self, urgency: str) -> int:
        """æ ¹æ®ç´§æ€¥ç¨‹åº¦åŠ¨æ€è°ƒæ•´æŸ¥è¯¢æ—¶é—´èŒƒå›´"""
        urgency_map = {
            'é«˜': 7,  # åªå…³æ³¨æœ€è¿‘7å¤©
            'ä¸­': 30,  # å…³æ³¨ä¸€ä¸ªæœˆ
            'ä½': 90  # å…³æ³¨ä¸€ä¸ªå­£åº¦
        }
        return urgency_map.get(urgency, 30)

    def _analyze_study_patterns(self, study_sessions: List[Dict]) -> Dict:
        """åˆ†æç”¨æˆ·çš„å­¦ä¹ æ¨¡å¼"""
        if not study_sessions:
            return {"pattern": "æ— è¶³å¤Ÿæ•°æ®", "efficiency": "æœªçŸ¥"}

        # ç®€å•çš„æ¨¡å¼åˆ†æï¼ˆå®é™…å¯ä»¥æ›´å¤æ‚ï¼‰
        total_duration = sum(s.get('duration_minutes', 0) for s in study_sessions)
        avg_duration = total_duration / len(study_sessions) if study_sessions else 0

        return {
            "average_session_length": f"{avg_duration:.1f}åˆ†é’Ÿ",
            "total_sessions": len(study_sessions),
            "pattern": "è§„å¾‹å­¦ä¹ " if len(study_sessions) > 5 else "å¶å°”å­¦ä¹ "
        }

    # def knowledge(self, query: str, user_id: int = None) -> Dict:



    # mark_assignment_complete

    def action(self, action_input:ActionInput) -> ActionResult:
        if isinstance(action_input, dict):
            action = action_input.get("action")
            data = action_input.get("data")
        else:
            action = getattr(action_input, "action", None)
            data = getattr(action_input, "data", None)
        """
        Support transactional 'mark_assignment_complete'.
        Expected data: {'assignment_id': int, 'user_id': int}
        """
        try:
            if action == "mark_assignment_complete":
                if not data:
                    return {"status": "error", "message": "missing data"}
                aid = data.get('assignment_id')
                user_id = data.get('user_id')
                if not aid or not user_id:
                    return {"status": "error", "message": "assignment_id and user_id required"}

                raw_conn = self.assignment_dao.get_connection()

                # helper to run transaction given a real connection object
                def _run_with_conn(conn):
                    try:
                        conn.begin()
                        updated = self.assignment_dao.mark_complete(conn, assignment_id=aid)
                        success = bool(updated[0]) if isinstance(updated, (list, tuple)) else bool(updated)
                        if not success:
                            conn.rollback()
                            return {"status": "error", "message": "assignment not found or already completed"}

                        try:
                            if hasattr(self.task_tracking_dao, "adjust_counters"):
                                self.task_tracking_dao.adjust_counters(conn, user_id=user_id, delta_completed=1, delta_pending=-1)
                            else:
                                try:
                                    cursor_args = ()
                                    with conn.cursor(*cursor_args) as cur:
                                        cur.execute(
                                            "UPDATE task_tracking SET completed = COALESCE(completed,0) + %s, pending = COALESCE(pending,0) + %s WHERE user_id = %s",
                                            (1, -1, user_id)
                                        )
                                        if getattr(cur, "rowcount", 0) == 0:
                                            try:
                                                cur.execute(
                                                    "INSERT INTO task_tracking (user_id, completed, pending) VALUES (%s, %s, %s)",
                                                    (user_id, 1, 0)
                                                )
                                            except Exception:
                                                pass
                                except Exception:
                                    pass
                        except Exception:
                            pass

                        try:
                            self.agent_interaction_dao.insert(conn=conn,
                                                             user_id=user_id,
                                                             user_message=f"æ ‡è®°ä½œä¸š {aid} ä¸ºå®Œæˆ",
                                                             ai_response="(system) assignment marked complete",
                                                             ai_model=getattr(self.llm_config, 'model', None))
                        except TypeError:
                            try:
                                self.agent_interaction_dao.insert(user_id=user_id,
                                                                 user_message=f"æ ‡è®°ä½œä¸š {aid} ä¸ºå®Œæˆ",
                                                                 ai_response="(system) assignment marked complete",
                                                                 ai_model=getattr(self.llm_config, 'model', None))
                            except Exception:
                                pass
                        except Exception:
                            pass

                        conn.commit()
                        return {"status": "success", "message": "assignment marked complete"}
                    except Exception as tx_e:
                        try:
                            conn.rollback()
                        except Exception:
                            pass
                        return {"status": "error", "message": f"transaction failed: {tx_e}"}
                    finally:
                        try:
                            conn.close()
                        except Exception:
                            pass

                # If DAO returned a context-manager, use it to obtain the real conn
                if hasattr(raw_conn, "__enter__") and hasattr(raw_conn, "__exit__"):
                    try:
                        with raw_conn as conn:
                            return _run_with_conn(conn)
                    except Exception as e:
                        # raw_conn context manager failed before yielding or _run_with_conn returned error
                        return {"status": "error", "message": str(e)}
                else:
                    # raw_conn is already a real connection object
                    return _run_with_conn(raw_conn)

            return {"status": "error", "message": f"unknown action {action_type}"}
        except Exception as e:
            return {"status": "error", "message": str(e)}

    def progress(self, query: ProgressQuery) -> ProgressResult:
        """
        è¿›åº¦ä¸ç»Ÿè®¡æŸ¥è¯¢
        è¾“å…¥ï¼šç”¨æˆ·IDç­‰æŸ¥è¯¢æ¡ä»¶
        è¿”å›ï¼šå·²å®Œæˆã€å¾…åŠã€æ€»ä»»åŠ¡
        """
        try:
            user_id = getattr(query, 'user_id', None)

            if not user_id:
                return ProgressResult(
                    completed=0,
                    pending=0,
                    total=0,
                    details=[{"error": "éœ€è¦ç”¨æˆ·ID"}]
                )

            print(f"ğŸ“Š æŸ¥è¯¢ç”¨æˆ· {user_id} çš„å­¦ä¹ è¿›åº¦...")

            # ä½¿ç”¨DAOè·å–å„ç±»æ•°æ®
            assignment_stats = self.assignment_dao.get_assignment_progress_stats(user_id)
            study_stats = self.study_session_dao.get_study_session_stats(user_id)
            course_progress = self.user_course_dao.get_course_progress(user_id)
            upcoming_assignments = self.assignment_dao.get_upcoming_assignments(user_id)

            # è®¡ç®—æ€»ä½“è¿›åº¦
            total_completed = assignment_stats['completed']
            total_pending = assignment_stats['pending']
            total_tasks = total_completed + total_pending

            # æ„å»ºè¯¦ç»†ä¿¡æ¯
            details = self._build_progress_details(
                assignment_stats, study_stats, course_progress, upcoming_assignments
            )

            print(f"âœ… è¿›åº¦ç»Ÿè®¡å®Œæˆ: å·²å®Œæˆ {total_completed}, å¾…åŠ {total_pending}, æ€»è®¡ {total_tasks}")

            return ProgressResult(
                completed=total_completed,
                pending=total_pending,
                total=total_tasks,
                details=details
            )

        except Exception as e:
            print(f"âŒ è¿›åº¦æŸ¥è¯¢é”™è¯¯: {e}")
            return ProgressResult(
                completed=0,
                pending=0,
                total=0,
                details=[{"error": f"è¿›åº¦æŸ¥è¯¢å¤±è´¥: {str(e)}"}]
            )

    # åœ¨ planner_agent.py çš„ PlannerAgent ç±»ä¸­æ·»åŠ ä»¥ä¸‹æ–¹æ³•

    def _build_progress_details(self, assignment_stats: Dict, study_stats: Dict,
                                course_progress: List[Dict], upcoming_assignments: List[Dict]) -> List[Dict]:
        """æ„å»ºè¿›åº¦è¯¦ç»†ä¿¡æ¯"""
        details = []

        # 1. æ€»ä½“ç»Ÿè®¡
        completion_rate = round((assignment_stats['completed'] / assignment_stats['total'] * 100), 1) if \
        assignment_stats['total'] > 0 else 0

        details.append({
            'type': 'overall_stats',
            'total_assignments': assignment_stats['total'],
            'completed_assignments': assignment_stats['completed'],
            'pending_assignments': assignment_stats['pending'],
            'completion_rate': completion_rate
        })

        # 2. å­¦ä¹ æ´»åŠ¨ç»Ÿè®¡
        details.append({
            'type': 'study_activity',
            'total_sessions': study_stats['total_sessions'],
            'total_study_hours': study_stats['total_study_hours'],
            'average_session_minutes': study_stats['avg_duration'],
            'active_days': study_stats['active_days'],
            'period_days': study_stats['period_days']
        })

        # 3. å„è¯¾ç¨‹è¿›åº¦
        if course_progress:
            details.append({
                'type': 'course_progress',
                'courses': course_progress,
                'total_courses': len(course_progress)
            })

        # 4. è¿‘æœŸå¾…åŠäº‹é¡¹
        if upcoming_assignments:
            details.append({
                'type': 'upcoming_assignments',
                'count': len(upcoming_assignments),
                'assignments': upcoming_assignments[:5]  # åªæ˜¾ç¤ºæœ€è¿‘5ä¸ª
            })

        # 5. å­¦ä¹ å»ºè®®
        suggestions = self._generate_progress_suggestions(assignment_stats, study_stats)
        details.append({
            'type': 'suggestions',
            'recommendations': suggestions
        })

        return details

    def _generate_progress_suggestions(self, assignment_stats: Dict, study_stats: Dict) -> List[str]:
        """ç”Ÿæˆè¿›åº¦å»ºè®®"""
        suggestions = []

        completion_rate = (assignment_stats['completed'] / assignment_stats['total'] * 100) if assignment_stats[
                                                                                                   'total'] > 0 else 0

        if completion_rate < 50:
            suggestions.append("å½“å‰å®Œæˆç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜å…ˆå¤„ç†ä¸´è¿‘æˆªæ­¢æ—¥æœŸçš„ä½œä¸š")
        elif completion_rate > 80:
            suggestions.append("å®Œæˆç‡å¾ˆé«˜ï¼ç»§ç»­ä¿æŒè‰¯å¥½çš„å­¦ä¹ èŠ‚å¥")

        if study_stats['total_sessions'] == 0:
            suggestions.append("æœ€è¿‘30å¤©æ²¡æœ‰å­¦ä¹ è®°å½•ï¼Œå»ºè®®åˆ¶å®šè§„å¾‹çš„å­¦ä¹ è®¡åˆ’")
        elif study_stats['active_days'] < 10:
            suggestions.append("å­¦ä¹ å¤©æ•°è¾ƒå°‘ï¼Œå»ºè®®å¢åŠ æ¯å‘¨çš„å­¦ä¹ é¢‘ç‡")

        if assignment_stats['pending'] > 5:
            suggestions.append(f"å½“å‰æœ‰ {assignment_stats['pending']} ä¸ªå¾…åŠä½œä¸šï¼Œå»ºè®®åˆç†å®‰æ’æ—¶é—´")

        if not suggestions:
            suggestions.append("å­¦ä¹ è¿›åº¦è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰çš„å­¦ä¹ èŠ‚å¥")

        return suggestions